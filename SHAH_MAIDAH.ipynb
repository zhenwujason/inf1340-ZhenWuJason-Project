{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPb1wPZ/pA6ukt2oML4BpvN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maidahshah/inf1340-programmingfordatascience-fa22/blob/main/SHAH_MAIDAH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Maidah Shah**  \n",
        "Assignment 1: Midterm Project, Tidying UN Dataset   \n",
        "INF1340, Fall 2022   \n",
        "November 9, 2022\n",
        "\n",
        "\n",
        "**Link:** "
      ],
      "metadata": {
        "id": "kQo4O_PI4mCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 1 ###\n",
        "# Upload the dataset to google colab.\n",
        "\n",
        "# Examine the raw data. As there are 6 tables, each in seperate tabs, we will split the dataset and store each split as a data frame.\n",
        "# Tabs: \"CONTENTS\", \"ANNEX\", and \"NOTES\" do not need to be split as they just contain supplementary information to help interpret the data. \n",
        "\n",
        "import pandas as pd # Import library to read and split the data file, as well as to perform other functions later.\n",
        "data = pd.ExcelFile(\"/content/UN_MigrantStockTotal_2015.xlsx\") # Read in the data using ExcelFile as the file is in an xlsx format.\n",
        "\n",
        "# Split each tab into a data frame containing one table using read_excel for the xlsx format. There will be 6 data frames in total, one for each tab/table. \n",
        "# Tab numbers correspond to table numbers. We will set the data frame numbers to match.\n",
        "# Skip the first 14 rows in each data frame as they do not contain data.\n",
        "df1orig = pd.read_excel(data, sheet_name='Table 1', skiprows=range(14)) # The \"orig\" stands for original as we will copy the data frames later and the original will remain unchanged.\n",
        "df2orig = pd.read_excel(data, sheet_name='Table 2', skiprows=range(14))\n",
        "df3orig = pd.read_excel(data, sheet_name='Table 3', skiprows=range(14))\n",
        "df4orig = pd.read_excel(data, sheet_name='Table 4', skiprows=range(14))\n",
        "df5orig = pd.read_excel(data, sheet_name='Table 5', skiprows=range(14))\n",
        "df6orig = pd.read_excel(data, sheet_name='Table 6', skiprows=range(14))"
      ],
      "metadata": {
        "id": "8rhNkhNOgubj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 2 ###\n",
        "# Examine the table for violations of tidy data principles. We will start with df1.\n",
        "\n",
        "df1orig.head()\n",
        "\n",
        "# Tidy Data Principle 1: Each observation forms a row.\n",
        "# Tidy Data Principle 2: Each variable forms its own column.\n",
        "# Tidy Data Principle 3: Variables need to be in cells, not rows and columns. \n",
        "# Tidy Data Principle 4: Each table column needs to have a singular data type.\n",
        "# Tidy Data Principle 5: A single observational unit must be in one table.\n",
        "\n",
        "# FINDINGS: \n",
        "# We can see that the migrant stock/sex headers are not merged or labelled for all the years. \n",
        "# There appear to be two header rows with stock/sex and year as the only multilevel headers in the data frame. \n",
        "# Migrant stock, sex, and year are three unique variables.\n",
        "# The \"Sort order\", \"Major area, region, country or area of destination\", \"Notes\", \"Country code\", and \"Type of data (a)\" columns repeat in each data frame, except for \"Type of data (a)\" in df2. \n",
        "# A unique identifier column, \"Sort order\" is already present in each data frame, so \"Major area, region, country or area of destination\" and \"Country code\" appear redundant.\n",
        "# \"Notes\" and \"Type of data (a)\" seem to be supplementary details to help interpret the data.\n",
        "\n",
        "# VIOLATIONS: \n",
        "# Each observation does not form a row, as the year variable is embedded in a row and the sex columns are not all labelled. \n",
        "# Column headers are values that contain useful information and not variable names (e.g., Male, 1990), and each variable does not have its own column.\n",
        "# Variables are stored in rows and columns (i.e., sex, year).\n",
        "# Multiple variables and data types are stored in one column (i.e., sex, year).\n",
        "# There are multiple observational units in the table (i.e., area/region/country, migrant stock)\n",
        "\n",
        "# PLAN:\n",
        "# We will combine the stock, sex, and year headers into a variable to enable the removal of the second header row with years.\n",
        "# We will then melt the header into three variables and columns.\n",
        "# We will then split the data frame into two tables for df1. One for area/region/country, and the second for migrant stock.\n",
        "# For df2-df6, we will remove the \"Major area, region, country or area of destination\", \"Notes\", \"Country code\", and \"Type of data (a)\" columns where present in each data frame. \n",
        "# If we need these columns at any point, we can append them back to our data frame as we will create a separate table with them for df1.  "
      ],
      "metadata": {
        "id": "5wwIS3bzNlQu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "309262d6-b12d-440a-b446-04fdeb9a3ce8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Sort\\norder Major area, region, country or area of destination Notes  \\\n",
              "0          NaN                                                NaN   NaN   \n",
              "1          1.0                                              WORLD   NaN   \n",
              "2          2.0                                  Developed regions   (b)   \n",
              "3          3.0                                 Developing regions   (c)   \n",
              "4          4.0                          Least developed countries   (d)   \n",
              "\n",
              "   Country code Type of data (a)  \\\n",
              "0           NaN              NaN   \n",
              "1         900.0              NaN   \n",
              "2         901.0              NaN   \n",
              "3         902.0              NaN   \n",
              "4         941.0              NaN   \n",
              "\n",
              "  International migrant stock at mid-year (both sexes) Unnamed: 6 Unnamed: 7  \\\n",
              "0                                               1990         1995       2000   \n",
              "1                                          152563212    160801752  172703309   \n",
              "2                                           82378628     92306854  103375363   \n",
              "3                                           70184584     68494898   69327946   \n",
              "4                                           11075966     11711703   10077824   \n",
              "\n",
              "  Unnamed: 8  Unnamed: 9  ...  Unnamed: 13 Unnamed: 14 Unnamed: 15  \\\n",
              "0       2005        2010  ...         2000        2005        2010   \n",
              "1  191269100   221714243  ...     87884839    97866674   114613714   \n",
              "2  117181109   132560325  ...     50536796    57217777    64081077   \n",
              "3   74087991    89153918  ...     37348043    40648897    50532637   \n",
              "4    9809634    10018128  ...      5361902     5383009     5462714   \n",
              "\n",
              "  Unnamed: 16 International migrant stock at mid-year (female)  Unnamed: 18  \\\n",
              "0        2015                                             1990         1995   \n",
              "1   126115435                                         74815702     79064275   \n",
              "2    67618619                                         42115231     47214055   \n",
              "3    58496816                                         32700471     31850220   \n",
              "4     6463217                                          5236216      5573685   \n",
              "\n",
              "   Unnamed: 19 Unnamed: 20 Unnamed: 21 Unnamed: 22  \n",
              "0         2000        2005        2010        2015  \n",
              "1     84818470    93402426   107100529   117584801  \n",
              "2     52838567    59963332    68479248    72863336  \n",
              "3     31979903    33439094    38621281    44721465  \n",
              "4      4721920     4432371     4560536     5493028  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4d5da4e-cf0f-4973-b090-255bef7c5b7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sort\\norder</th>\n",
              "      <th>Major area, region, country or area of destination</th>\n",
              "      <th>Notes</th>\n",
              "      <th>Country code</th>\n",
              "      <th>Type of data (a)</th>\n",
              "      <th>International migrant stock at mid-year (both sexes)</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>Unnamed: 9</th>\n",
              "      <th>...</th>\n",
              "      <th>Unnamed: 13</th>\n",
              "      <th>Unnamed: 14</th>\n",
              "      <th>Unnamed: 15</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "      <th>International migrant stock at mid-year (female)</th>\n",
              "      <th>Unnamed: 18</th>\n",
              "      <th>Unnamed: 19</th>\n",
              "      <th>Unnamed: 20</th>\n",
              "      <th>Unnamed: 21</th>\n",
              "      <th>Unnamed: 22</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1990</td>\n",
              "      <td>1995</td>\n",
              "      <td>2000</td>\n",
              "      <td>2005</td>\n",
              "      <td>2010</td>\n",
              "      <td>...</td>\n",
              "      <td>2000</td>\n",
              "      <td>2005</td>\n",
              "      <td>2010</td>\n",
              "      <td>2015</td>\n",
              "      <td>1990</td>\n",
              "      <td>1995</td>\n",
              "      <td>2000</td>\n",
              "      <td>2005</td>\n",
              "      <td>2010</td>\n",
              "      <td>2015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>WORLD</td>\n",
              "      <td>NaN</td>\n",
              "      <td>900.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>152563212</td>\n",
              "      <td>160801752</td>\n",
              "      <td>172703309</td>\n",
              "      <td>191269100</td>\n",
              "      <td>221714243</td>\n",
              "      <td>...</td>\n",
              "      <td>87884839</td>\n",
              "      <td>97866674</td>\n",
              "      <td>114613714</td>\n",
              "      <td>126115435</td>\n",
              "      <td>74815702</td>\n",
              "      <td>79064275</td>\n",
              "      <td>84818470</td>\n",
              "      <td>93402426</td>\n",
              "      <td>107100529</td>\n",
              "      <td>117584801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>Developed regions</td>\n",
              "      <td>(b)</td>\n",
              "      <td>901.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>82378628</td>\n",
              "      <td>92306854</td>\n",
              "      <td>103375363</td>\n",
              "      <td>117181109</td>\n",
              "      <td>132560325</td>\n",
              "      <td>...</td>\n",
              "      <td>50536796</td>\n",
              "      <td>57217777</td>\n",
              "      <td>64081077</td>\n",
              "      <td>67618619</td>\n",
              "      <td>42115231</td>\n",
              "      <td>47214055</td>\n",
              "      <td>52838567</td>\n",
              "      <td>59963332</td>\n",
              "      <td>68479248</td>\n",
              "      <td>72863336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>Developing regions</td>\n",
              "      <td>(c)</td>\n",
              "      <td>902.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>70184584</td>\n",
              "      <td>68494898</td>\n",
              "      <td>69327946</td>\n",
              "      <td>74087991</td>\n",
              "      <td>89153918</td>\n",
              "      <td>...</td>\n",
              "      <td>37348043</td>\n",
              "      <td>40648897</td>\n",
              "      <td>50532637</td>\n",
              "      <td>58496816</td>\n",
              "      <td>32700471</td>\n",
              "      <td>31850220</td>\n",
              "      <td>31979903</td>\n",
              "      <td>33439094</td>\n",
              "      <td>38621281</td>\n",
              "      <td>44721465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Least developed countries</td>\n",
              "      <td>(d)</td>\n",
              "      <td>941.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11075966</td>\n",
              "      <td>11711703</td>\n",
              "      <td>10077824</td>\n",
              "      <td>9809634</td>\n",
              "      <td>10018128</td>\n",
              "      <td>...</td>\n",
              "      <td>5361902</td>\n",
              "      <td>5383009</td>\n",
              "      <td>5462714</td>\n",
              "      <td>6463217</td>\n",
              "      <td>5236216</td>\n",
              "      <td>5573685</td>\n",
              "      <td>4721920</td>\n",
              "      <td>4432371</td>\n",
              "      <td>4560536</td>\n",
              "      <td>5493028</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4d5da4e-cf0f-4973-b090-255bef7c5b7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4d5da4e-cf0f-4973-b090-255bef7c5b7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4d5da4e-cf0f-4973-b090-255bef7c5b7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 3 ###\n",
        "\n",
        "# We will first copy each data frame and make changes to the copy, so if needed, we can refer to the original data frame at any point.\n",
        "\n",
        "df1 = df1orig.copy(deep=True)\n",
        "df2 = df2orig.copy(deep=True)\n",
        "df3 = df3orig.copy(deep=True)\n",
        "df4 = df4orig.copy(deep=True)\n",
        "df5 = df5orig.copy(deep=True)\n",
        "df6 = df6orig.copy(deep=True)"
      ],
      "metadata": {
        "id": "Xfv2UW6-h1tI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 4 ###\n",
        "\n",
        "# Remove the \"Major area, region, country or area of destination\", \"Notes\", \"Country code\", and \"Type of data (a)\" columns where present in each data frame, except for df1.\n",
        "\n",
        "df2.drop(columns=['Major area, region, country or area of destination','Notes','Country code'], inplace=True)\n",
        "df3.drop(columns=['Major area, region, country or area of destination','Notes','Country code','Type of data (a)'], inplace=True)\n",
        "df4.drop(columns=['Major area, region, country or area of destination','Notes','Country code','Type of data (a)'], inplace=True)\n",
        "df5.drop(columns=['Major area, region, country or area of destination','Notes','Country code','Type of data (a)'], inplace=True)\n",
        "df6.drop(columns=['Major area, region, country or area of destination','Notes','Country code','Type of data (a)'], inplace=True)"
      ],
      "metadata": {
        "id": "xnfAT4Cfiev9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 5 ###\n",
        "\n",
        "# Working on df1.\n",
        "# Start by assigning column names to all the migrant stock/sex columns, and abbreviate the sex to an initial to simplify splitting of the variable name later.\n",
        "\n",
        "for i in range(5,23): # This is the range of stock/sex columns.\n",
        "\n",
        "  if i in range(5,11):\n",
        "    df1.columns.values[i] = \"B\" # B for both sexes.\n",
        "  elif i in range (11,17):\n",
        "    df1.columns.values[i] = \"M\" # M for male.\n",
        "  else:\n",
        "    df1.columns.values[i] = \"F\" # F for female."
      ],
      "metadata": {
        "id": "70Jexd6Wz3VF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 6 ###\n",
        "\n",
        "# Bring up the year data from the second header row and append it with the sex to enable deletion of the year row later.\n",
        "\n",
        "for j in range(5,23):\n",
        "\n",
        "  if j in [5,11,17]: # Corresponds to columns with year value 1990 and so on for each year below.\n",
        "    df1.columns.values[j] = df1.columns.values[j] + \"1990\"\n",
        "  elif j in [6,12,18]:\n",
        "    df1.columns.values[j] = df1.columns.values[j] + \"1995\"\n",
        "  elif j in [7,13,19]:\n",
        "    df1.columns.values[j] = df1.columns.values[j] + \"2000\"\n",
        "  elif j in [8,14,20]:\n",
        "    df1.columns.values[j] = df1.columns.values[j] + \"2005\"\n",
        "  elif j in [9,15,21]:\n",
        "    df1.columns.values[j] = df1.columns.values[j] + \"2010\"\n",
        "  else:\n",
        "    df1.columns.values[j] = df1.columns.values[j] + \"2015\""
      ],
      "metadata": {
        "id": "86_t3FhSyFQF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 7 ###\n",
        "\n",
        "# Confirm that the variable names appear as desired, i.e., \"Sex + Year\", and that they correspond to the correct sex and year columns.\n",
        "\n",
        "df1.head(2)"
      ],
      "metadata": {
        "id": "D9llEFVbyatF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 8 ###\n",
        "\n",
        "# Remove the second header row with the year information as that data is now included in the first header row.\n",
        "\n",
        "df1.drop([0],inplace=True)\n",
        "df1.head(2) # Confirm that the row was removed."
      ],
      "metadata": {
        "id": "9tHEEub3bkle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 9 ###\n",
        "\n",
        "# Melt the sex/year from column headers to values in a column. \n",
        "\n",
        "df1 = df1.melt(id_vars = ['Sort\\norder', 'Major area, region, country or area of destination','Notes','Country code','Type of data (a)'], var_name = \"sex_yr\", value_name = \"International migrant stock at mid-year\")\n",
        "df1.head() # Confirm that the values were pivoted."
      ],
      "metadata": {
        "id": "1Hf7QM49bq3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 10 ###\n",
        "\n",
        "# Split sex and year into two variables and columns using the lambda function, also enabling each observation to form a row.\n",
        "\n",
        "df1 = df1.assign(Sex = lambda x: x.sex_yr.str[0].astype(str), Year = lambda x: x.sex_yr.str[1:].astype(str)).drop(\"sex_yr\",axis=1) \n",
        "df1.head() # Confirm that the variable was split as desired."
      ],
      "metadata": {
        "id": "GcTbi-A-cIXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 11a ###\n",
        "\n",
        "# We will create two tables so that a single observaional unit is in one table.\n",
        "# Table 1 will contain area/region/country with details of each area.\n",
        "# Table 2 will contain the rest of the sex, year, and migrant stock data.\n",
        "\n",
        "table1 = df1.iloc[:,:-3] # Remove the last three columns.\n",
        "table2 = df1.iloc[:,[0,5,6,7]] # Keep the first column as the unique id, and the last three columns."
      ],
      "metadata": {
        "id": "wzrZR6Mhmkeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 11b ###\n",
        "\n",
        "# Confirm that the table was split as desired, and that it is tidy. Look at header and tail data.\n",
        "\n",
        "table1"
      ],
      "metadata": {
        "id": "mAfYwWRZ1lWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 11c ###\n",
        "\n",
        "# Confirm that the table was split as desired, and that it is tidy. Look at header and tail data. \n",
        "\n",
        "table2"
      ],
      "metadata": {
        "id": "uzX3f2cE2f9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 12a ###\n",
        "\n",
        "# We will now examine df2 to ensure that the columns outlined above were removed and for violations of tidy data principles.\n",
        "\n",
        "df2.head()\n",
        "\n",
        "# FINDINGS: \n",
        "# We can see that df2 is similar to df1, except for the columns that were deleted and table header titles. \n",
        "# However, because of the columns that were deleted in df2, there is a single observational unit in the table, so we will not need to split the table in 2 as in step 11a. \n",
        "\n",
        "# VIOLATIONS:\n",
        "# df2 violates the same tidy data principles detailed above for df1 in step 2 with the exception of the multiple obervational units in one table.\n",
        "\n",
        "# PLAN: \n",
        "# We will apply the same rules and code from df1 to tidy df2 with the exception of the table splitting in step 11a. "
      ],
      "metadata": {
        "id": "0TJAStXL2vVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 12b ###\n",
        "\n",
        "# Working on df2.\n",
        "\n",
        "# Assign column names to all migrant stock/sex columns as in step 5.\n",
        "for i in range(1,19): # Adjust range for df2.\n",
        "\n",
        "  if i in range(1,7):\n",
        "    df2.columns.values[i] = \"B\" \n",
        "  elif i in range (7,13):\n",
        "    df2.columns.values[i] = \"M\"\n",
        "  else:\n",
        "    df2.columns.values[i] = \"F\"\n",
        "\n",
        "# Append sex and year data as in step 6.\n",
        "for j in range(1,19): # Adjust range for df2.\n",
        "\n",
        "  if j in [1,7,13]:\n",
        "    df2.columns.values[j] = df2.columns.values[j] + \"1990\"\n",
        "  elif j in [2,8,14]:\n",
        "    df2.columns.values[j] = df2.columns.values[j] + \"1995\"\n",
        "  elif j in [3,9,15]:\n",
        "    df2.columns.values[j] = df2.columns.values[j] + \"2000\"\n",
        "  elif j in [4,10,16]:\n",
        "    df2.columns.values[j] = df2.columns.values[j] + \"2005\"\n",
        "  elif j in [5,11,17]:\n",
        "    df2.columns.values[j] = df2.columns.values[j] + \"2010\"\n",
        "  else:\n",
        "    df2.columns.values[j] = df2.columns.values[j] + \"2015\"\n",
        "\n",
        "# Remove the second header row as in step 8. \n",
        "df2.drop([0],inplace=True)\n",
        "\n",
        "# Melt the sex/year from column headers to values in a column as in step 9. \n",
        "df2 = df2.melt(id_vars = ['Sort\\norder'], var_name = \"sex_yr\", value_name = \"Total population at mid-year (thousands)\") # Adjust column and value names for df2.\n",
        "\n",
        "# Split sex and year into two variables and columns as in step 10.\n",
        "df2 = df2.assign(Sex = lambda x: x.sex_yr.str[0].astype(str), Year = lambda x: x.sex_yr.str[1:].astype(str)).drop(\"sex_yr\",axis=1) \n",
        "\n",
        "# Confirm that the table is tidy. Look at header and tail data.\n",
        "df2"
      ],
      "metadata": {
        "id": "B_vZq22x3af9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 13a ###\n",
        "\n",
        "# We will now examine df3 to ensure that the columns outlined above were removed and for violations of tidy data principles.\n",
        "\n",
        "df3.head()\n",
        "\n",
        "# FINDINGS: \n",
        "# We can see that df3 is almost identical to df1, with the exception of the columns that were deleted and table header titles. \n",
        "# However, because of the columns that were deleted in df3, there is a single observational unit in the table, so we will not need to split the table in 2 as in step 11a. \n",
        "\n",
        "# VIOLATIONS:\n",
        "# df3 violates the same tidy data principles detailed above for df1 in step 2 with the exception of the multiple obervational units in one table.\n",
        "\n",
        "# PLAN: \n",
        "# We will apply the same rules and code from df1 to tidy df3 with the exception of the table splitting in step 11a. "
      ],
      "metadata": {
        "id": "PVmT2udWeAnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 13b ###\n",
        "\n",
        "# Working on df3.\n",
        "\n",
        "# Assign column names to all migrant stock/sex columns as in step 5.\n",
        "for i in range(1,19): # Adjust range for df3.\n",
        "\n",
        "  if i in range(1,7):\n",
        "    df3.columns.values[i] = \"B\" \n",
        "  elif i in range (7,13):\n",
        "    df3.columns.values[i] = \"M\"\n",
        "  else:\n",
        "    df3.columns.values[i] = \"F\"\n",
        "\n",
        "# Append sex and year data as in step 6.\n",
        "for j in range(1,19): # Adjust range for df3.\n",
        "\n",
        "  if j in [1,7,13]:\n",
        "    df3.columns.values[j] = df3.columns.values[j] + \"1990\"\n",
        "  elif j in [2,8,14]:\n",
        "    df3.columns.values[j] = df3.columns.values[j] + \"1995\"\n",
        "  elif j in [3,9,15]:\n",
        "    df3.columns.values[j] = df3.columns.values[j] + \"2000\"\n",
        "  elif j in [4,10,16]:\n",
        "    df3.columns.values[j] = df3.columns.values[j] + \"2005\"\n",
        "  elif j in [5,11,17]:\n",
        "    df3.columns.values[j] = df3.columns.values[j] + \"2010\"\n",
        "  else:\n",
        "    df3.columns.values[j] = df3.columns.values[j] + \"2015\"\n",
        "\n",
        "# Remove the second header row as in step 8. \n",
        "df3.drop([0],inplace=True)\n",
        "\n",
        "# Melt the sex/year from column headers to values in a column as in step 9. \n",
        "df3 = df3.melt(id_vars = ['Sort\\norder'], var_name = \"sex_yr\", value_name = \"International migrant stock as a percentage of total population\") # Adjust column and value names for df3.\n",
        "\n",
        "# Split sex and year into two variables and columns as in step 10.\n",
        "df3 = df3.assign(Sex = lambda x: x.sex_yr.str[0].astype(str), Year = lambda x: x.sex_yr.str[1:].astype(str)).drop(\"sex_yr\",axis=1) \n",
        "\n",
        "# Confirm that the table is tidy. Look at header and tail data.\n",
        "df3"
      ],
      "metadata": {
        "id": "gKtJoOnDhZV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 14a ###\n",
        "\n",
        "# We will now examine df4 to ensure that the columns outlined above were removed and for violations of tidy data principles.\n",
        "\n",
        "df4.head()\n",
        "\n",
        "# FINDINGS: \n",
        "# We can see that df4 differs from df1 as it is only measuring migrant stock for females, not males and both sexes.\n",
        "# As such, there are much fewer columns.\n",
        "# However, because of the columns that were deleted in df4, there is a single observational unit in the table, so we will not need to split the table in 2 as in step 11a. \n",
        "\n",
        "# VIOLATIONS:\n",
        "# df4 violates the same tidy data principles detailed above for df1 in step 2 with the exception of the multiple obervational units in one table.\n",
        "\n",
        "# PLAN: \n",
        "# We will simplify and apply the same rules and code from df1 to tidy df4 to account for two fewer sexes, and with the exception of the table splitting in step 11a.\n",
        "# We cannot skip the creation of a sex variable and column even though there is only one sex as the table header cannot contain valuable information, i.e., female in this case.\n",
        "# Also, each variable must form its own column."
      ],
      "metadata": {
        "id": "EhzP7RBcj_wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 14b ###\n",
        "\n",
        "# Working on df4.\n",
        "\n",
        "# Assign column names to all migrant stock/sex columns as in step 5.\n",
        "# However, consider that there is only one sex to account for. Simplify the code to reflect this.\n",
        "for i in range(1,7): # Adjust range for df4.\n",
        "\n",
        "  if i in range(1,7):\n",
        "    df4.columns.values[i] = \"F\" # Female is the only sex option in df4.\n",
        "\n",
        "# Append sex and year data as in step 6. \n",
        "# However, we can simplify by removing the for loop and if/elif/else statements and directly append the columns as there are only a few. \n",
        "df4.columns.values[1] = df4.columns.values[1] + \"1990\"\n",
        "df4.columns.values[2] = df4.columns.values[2] + \"1995\"\n",
        "df4.columns.values[3] = df4.columns.values[3] + \"2000\"\n",
        "df4.columns.values[4] = df4.columns.values[4] + \"2005\"\n",
        "df4.columns.values[5] = df4.columns.values[5] + \"2010\"\n",
        "df4.columns.values[6] = df4.columns.values[6] + \"2015\"\n",
        "\n",
        "# Remove the second header row as in step 8. \n",
        "df4.drop([0],inplace=True)\n",
        "\n",
        "# Melt the sex/year from column headers to values in a column as in step 9. \n",
        "df4 = df4.melt(id_vars = ['Sort\\norder'], var_name = \"sex_yr\", value_name = \"Migrants as a percentage of the international migrant stock\") # Adjust column and value names for df4.\n",
        "\n",
        "# Split sex and year into two variables and columns as in step 10.\n",
        "df4 = df4.assign(Sex = lambda x: x.sex_yr.str[0].astype(str), Year = lambda x: x.sex_yr.str[1:].astype(str)).drop(\"sex_yr\",axis=1) \n",
        "\n",
        "# Confirm that the table is tidy. Look at header and tail data.\n",
        "df4"
      ],
      "metadata": {
        "id": "C-ru4dfmtUJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 15a ###\n",
        "\n",
        "# We will now examine df5 to ensure that the columns outlined above were removed and for violations of tidy data principles.\n",
        "\n",
        "df5.head()\n",
        "\n",
        "# FINDINGS: \n",
        "# We can see that df5 is similar to df1, with the exception of the columns that were deleted, table header titles, and one less column for each sex/year as the years are in ranges. \n",
        "# However, because of the columns that were deleted in df5, there is a single observational unit in the table, so we will not need to split the table in 2 as in step 11a. \n",
        "\n",
        "# VIOLATIONS:\n",
        "# df5 violates the same tidy data principles detailed above for df1 in step 2 with the exception of the multiple obervational units in one table.\n",
        "\n",
        "# PLAN: \n",
        "# We will apply the same rules and code from df1 to tidy df5 with the exception of the table splitting in step 11a. \n",
        "# We will also need to consider that the years are in ranges, which creates one less sex/year column per sex, shifting the indices. "
      ],
      "metadata": {
        "id": "RdwTkAhJx5CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 15b ###\n",
        "\n",
        "# Working on df5.\n",
        "\n",
        "# Assign column names to all migrant stock/sex columns as in step 5.\n",
        "for i in range(1,16): # Adjust range for df5.\n",
        "\n",
        "  if i in range(1,6):\n",
        "    df5.columns.values[i] = \"B\" \n",
        "  elif i in range (6,11):\n",
        "    df5.columns.values[i] = \"M\"\n",
        "  else:\n",
        "    df5.columns.values[i] = \"F\"\n",
        "\n",
        "# Append sex and year data as in step 6.\n",
        "for j in range(1,16): # Adjust range for df3.\n",
        "\n",
        "  if j in [1,6,11]:\n",
        "    df5.columns.values[j] = df5.columns.values[j] + \"1990-1995\"\n",
        "  elif j in [2,7,12]:\n",
        "    df5.columns.values[j] = df5.columns.values[j] + \"1995-2000\"\n",
        "  elif j in [3,8,13]:\n",
        "    df5.columns.values[j] = df5.columns.values[j] + \"2000-2005\"\n",
        "  elif j in [4,9,14]:\n",
        "    df5.columns.values[j] = df5.columns.values[j] + \"2005-2010\"\n",
        "  else:\n",
        "    df5.columns.values[j] = df5.columns.values[j] + \"2010-2015\"\n",
        "\n",
        "# Remove the second header row as in step 8. \n",
        "df5.drop([0],inplace=True)\n",
        "\n",
        "# Melt the sex/year from column headers to values in a column as in step 9. \n",
        "df5 = df5.melt(id_vars = ['Sort\\norder'], var_name = \"sex_yr\", value_name = \"Annual rate of change of the migrant stock\") # Adjust column and value names for df5.\n",
        "\n",
        "# Split sex and year into two variables and columns as in step 10.\n",
        "df5 = df5.assign(Sex = lambda x: x.sex_yr.str[0].astype(str), Years = lambda x: x.sex_yr.str[1:].astype(str)).drop(\"sex_yr\",axis=1) # Adjust column and value names for df5.\n",
        "\n",
        "# Confirm that the table is tidy. Look at header data.\n",
        "df5"
      ],
      "metadata": {
        "id": "vL8bEuFbykoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 16a ###\n",
        "\n",
        "# We will now examine df6 to ensure that the columns outlined above were removed and for violations of tidy data principles.\n",
        "\n",
        "df6.head()\n",
        "\n",
        "# FINDINGS: \n",
        "# We can see that df6 differs from df1 as it seems that we are measuring 3 observational units in the table, so we will need to split the table in 3, similar to step 11a. \n",
        "# The first table is the only observational unit that includes sex as a variable.\n",
        "# It will only be measuring migrant stock for both sexes, and not males and females separately.\n",
        "\n",
        "# VIOLATIONS:\n",
        "# df3 violates the same tidy data principles detailed above for df1 in step 2, including the violation of having multiple obervational units in one table.\n",
        "\n",
        "# PLAN: \n",
        "# We will start out by splitting the data frame into 3 separate tables. \n",
        "# Unlike for df1 in step 11a where we split after cleaning, we will split first here as each observational unit and table will require different steps to tidy.\n",
        "# For the first table, there will only be one possible sex value, \"both sexes\", so we can use similar code from df4 in step 14b where there was also only one possible sex value.\n",
        "# For the second and third tables, as there are no sex variables, we will only need to create year variables. "
      ],
      "metadata": {
        "id": "-ITm-UO10TKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 16b ###\n",
        "\n",
        "# Working on df6.\n",
        "\n",
        "# We will create three tables so that a single observaional unit is in one table.\n",
        "# Table 1 will contain the obervational unit, estimated refugee stock.\n",
        "# Table 2 will contain the obervational unit, refugees as a percentage of the international migrant stock.\n",
        "# Table 3 will contain the obervational unit, annual rate of change of the refugee stock.\n",
        "\n",
        "# Table 1 for df6. Ensure that table names are distiniguishable from table names for df1 in step 11a. \n",
        "df6_table1orig = df6.iloc[:,:-11] # Remove the last eleven columns. The \"orig\" stands for original as we will copy the table so that the original table remains unchanged.\n",
        "df6_table1 = df6_table1orig.copy(deep=True) # Make a copy.\n",
        "df6_table1.head() # Confirm that the table was split as desired. Look at header data."
      ],
      "metadata": {
        "id": "d6ghF76A98HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 16c ###\n",
        "\n",
        "# Table 2 for df6. \n",
        "df6_table2orig = df6.iloc[:,[0,7,8,9,10,11,12]] # Keep the first column as the unique id, and the second observational unit columns.\n",
        "df6_table2 = df6_table2orig.copy(deep=True) # Make a copy.\n",
        "df6_table2.head() # Confirm that the table was split as desired. Look at header data."
      ],
      "metadata": {
        "id": "DOc8Ft7bAUOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 16d ###\n",
        "\n",
        "# Table 3 for df6. \n",
        "df6_table3orig = df6.iloc[:,[0,13,14,15,16,17]] # Keep the first column as the unique id, and the third observational unit columns.\n",
        "df6_table3 = df6_table3orig.copy(deep=True) # Make a copy.\n",
        "df6_table3.head() # Confirm that the table was split as desired. Look at header data."
      ],
      "metadata": {
        "id": "aJWTh23UA5uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 16e ###\n",
        "\n",
        "# Working on df6_table1.\n",
        "\n",
        "# Assign column names to all migrant stock/sex columns as in step 5.\n",
        "# However, consider that there is only one sex to account for. Simplify the code to reflect this.\n",
        "for i in range(1,7): # Adjust range for df6, first observational unit.\n",
        "\n",
        "  if i in range(1,7):\n",
        "    df6_table1.columns.values[i] = \"B\" # Both is the only sex option for the first observational unit in df6.\n",
        "\n",
        "# Append sex and year data as in step 6. \n",
        "# However, we can simplify by removing the for loop and if/elif/else statements and directly append the columns as there are only a few. \n",
        "df6_table1.columns.values[1] = df6_table1.columns.values[1] + \"1990\"\n",
        "df6_table1.columns.values[2] = df6_table1.columns.values[2] + \"1995\"\n",
        "df6_table1.columns.values[3] = df6_table1.columns.values[3] + \"2000\"\n",
        "df6_table1.columns.values[4] = df6_table1.columns.values[4] + \"2005\"\n",
        "df6_table1.columns.values[5] = df6_table1.columns.values[5] + \"2010\"\n",
        "df6_table1.columns.values[6] = df6_table1.columns.values[6] + \"2015\"\n",
        "\n",
        "# Remove the second header row as in step 8. \n",
        "df6_table1.drop([0],inplace=True)\n",
        "\n",
        "# Melt the sex/year from column headers to values in a column as in step 9. \n",
        "df6_table1 = df6_table1.melt(id_vars = ['Sort\\norder'], var_name = \"sex_yr\", value_name = \"Estimated refugee stock at mid-year\") # Adjust column and value names for df6_table1.\n",
        "\n",
        "# Split sex and year into two variables and columns as in step 10.\n",
        "df6_table1 = df6_table1.assign(Sex = lambda x: x.sex_yr.str[0].astype(str), Year = lambda x: x.sex_yr.str[1:].astype(str)).drop(\"sex_yr\",axis=1) \n",
        "\n",
        "# Confirm that the table is tidy. Look at header and tail data.\n",
        "df6_table1"
      ],
      "metadata": {
        "id": "WSb70-vqBKWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 16f ###\n",
        "\n",
        "# Working on df6_table2.\n",
        "\n",
        "# Bring the year data from the second header row up to the first header row. \n",
        "# As we are not appending with sex or any other variable in this case, we can simply rename the columns.\n",
        "df6_table2.columns = ['Sort\\norder', '1990', '1995', '2000', '2005', '2010', '2015']\n",
        "\n",
        "# Remove the second header row as in step 8. \n",
        "df6_table2.drop([0],inplace=True)\n",
        "\n",
        "# Melt the year from column headers to values in a column as in step 9. \n",
        "df6_table2 = df6_table2.melt(id_vars = ['Sort\\norder'], var_name = \"Year\", value_name = \"Refugees as a percentage of the international migrant stock\") # Adjust column and value names for df6_table2.\n",
        "\n",
        "# Confirm that the table is tidy. Look at header and tail data.\n",
        "df6_table2"
      ],
      "metadata": {
        "id": "O_KirrhDFe4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### STEP 16g ###\n",
        "\n",
        "# Working on df6_table3.\n",
        "\n",
        "# Bring the year data from the second header row up to the first header row. \n",
        "# As we are not appending with sex or any other variable in this case, we can simply rename the columns.\n",
        "df6_table3.columns = ['Sort\\norder', '1990-1995', '1995-2000', '2000-2005', '2005-2010', '2010-2015']\n",
        "\n",
        "# Remove the second header row as in step 8. \n",
        "df6_table3.drop([0],inplace=True)\n",
        "\n",
        "# Melt the year from column headers to values in a column as in step 9. \n",
        "df6_table3 = df6_table3.melt(id_vars = ['Sort\\norder'], var_name = \"Years\", value_name = \"Annual rate of change of the refugee stock\") # Adjust column and value names for df6_table3.\n",
        "\n",
        "# Confirm that the table is tidy. Look at header and tail data.\n",
        "df6_table3"
      ],
      "metadata": {
        "id": "FUhOL3IyPwqP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}